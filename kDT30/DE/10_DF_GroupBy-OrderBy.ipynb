{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc872e2",
   "metadata": {},
   "source": [
    "## groupBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c02403",
   "metadata": {},
   "source": [
    "- groupBy  : 집계함수를 가지고 있는 GroupData 객체를 반환한다.  \n",
    "\n",
    "- GrouopData객체의 집계함수들을 사용해 grouping 된 데이터들의 집계결과를 저장하고 있는 DataFrame을 반환 받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437aec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94b8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592eccb-818f-4179-a59a-c2a2f0352016",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = spark.read.csv('/dataframe/a_class_info.csv', header=True)\n",
    "cdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c003818-bf76-4b08-b4f0-0a113b36e016",
   "metadata": {},
   "source": [
    "- 지역별 교육타입별(cdf.loc, cdf.teaching_type)) 학생 숫자(class_std_cnt)를 구해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae39d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf.groupby(cdf.loc, cdf.teaching_type).sum('class_std_cnt').show()\n",
    "# AnalysisException: \"class_std_cnt\" is not a numeric column.\n",
    "# class_std_cnt가 문자열이라 문제가 된다.\n",
    "# 스키마를 적용해서 해결 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaaa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스키마 설정 후 dataload\n",
    "schema = StructType([\n",
    "        StructField('class_cd',StringType()),\n",
    "        StructField('school',StringType()),\n",
    "        StructField('class_std_cnt',IntegerType()),    \n",
    "        StructField('loc',StringType()),\n",
    "        StructField('school_type',StringType()),\n",
    "        StructField('teaching_type',StringType())    \n",
    "])\n",
    "\n",
    "cdf = spark.read.csv('/dataframe/a_class_info.csv', header=True, schema=schema)\n",
    "cdf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310c316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 지역에 따른 교육 타입별 학생수 추출\n",
    "cdf.groupBy(cdf.loc,cdf.teaching_type).sum('class_std_cnt').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('지역별 class 숫자를 계산해보자. 단 지역정보가 없는 데이터는 제외한다.')\n",
    "cdf.where(cdf.loc.isNotNull()) # 지역정보가 있는 데이터만 추출\n",
    "cdf.where(cdf.loc.isNotNull()).groupby(cdf.loc) # 지역별로 그룹핑(카테고리)\n",
    "cdf.where(cdf.loc.isNotNull()).groupby(cdf.loc).count() # 카테고리별 원소수를 개수한 결과가 df로 반환\n",
    "cdf.where(cdf.loc.isNotNull()).groupby(cdf.loc).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f177ea-5b8e-4d87-a403-9e0f110d80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('지역별 교육타입별 학생수의 합과 평균을 구해보자. 단 학생수의 합이 300미만인 데이터는 제외한다.')\n",
    "# 학생수의 합과 평균 : 두개의 집계함수를 동시에 사용해야 함 => agg() 사용해서 해결\n",
    "cdf.groupby(cdf.loc, cdf.teaching_type)\\\n",
    "    .agg(sum('class_std_cnt'),avg('class_std_cnt')).show(2) #지역별 교육타입별 학생수의 합과 평균을 구해보자\n",
    "\n",
    "cdf.groupby(cdf.loc, cdf.teaching_type)\\\n",
    "    .agg(sum('class_std_cnt'),avg('class_std_cnt'))\\\n",
    "    .where(col('sum(class_std_cnt)')>=300).show() #단 학생수의 합이 300미만인 데이터는 제외한다, agg 함수에서 계산한 결과를 활용해서 300이상인지 체크\n",
    "\n",
    "cdf.groupby(cdf.loc, cdf.teaching_type)\\\n",
    "    .agg(sum('class_std_cnt'),avg('class_std_cnt'))\\\n",
    "    .where(sum('class_std_cnt')>=300).show() # groupby된 객체를 이용해서 학생수의 합을 다시계산, agg에서 합을 계산, where에서 합을 계산\n",
    "\n",
    "# cdf.groupby(cdf.loc, cdf.teaching_type)\\\n",
    "#     .agg(sum('class_std_cnt'),avg('class_std_cnt'))\\\n",
    "#     .where('sum(class_std_cnt)'>=300)  # 컴럼명을 문자열로만 전달하는건 where/filter에서는 사용할 수 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('컬럼명이 sum(class_std_cnt) 이라니 너무 이상하다. 집계함수를 수행하고 별칭을 붙여보자')\n",
    "\n",
    "cdf.groupby(cdf.loc, cdf.teaching_type)\\\n",
    "    .agg(sum('class_std_cnt').alias('total'),avg('class_std_cnt').alias('avg'))\\\n",
    "    .where(col('total')>=300).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715766e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|(max(tot) - min(tot))|\n",
      "+---------------------+\n",
      "|                  368|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 지역별로 구한 학생 수 총합에 대해 학생이 가장많은 지역과 가장 적은 지역의 차이를 구해보자\n",
    "\n",
    "cdf.where(cdf.loc.isNotNull())\\\n",
    "   .groupby(cdf.loc)\\\n",
    "   .agg(sum('class_std_cnt').alias('student_tot')) # dataframe 반환, 연결 method max,min등의 집계함수는 연결 불가\n",
    "\n",
    "cdf.where(cdf.loc.isNotNull())\\\n",
    "   .groupby(cdf.loc)\\\n",
    "   .agg(sum('class_std_cnt').alias('student_tot'))\\\n",
    "   .select(max(col('student_tot'))-min(col('student_tot')))\\\n",
    "   .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ff469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby  사용 가능 집계함수\n",
    "cdf.where(cdf.loc.isNotNull())\\\n",
    "   .groupby(cdf.loc)\\\n",
    "   .agg(sum('class_std_cnt').alias('sum'),\n",
    "        avg('class_std_cnt').alias('avg'),\n",
    "        max('class_std_cnt').alias('max'),\n",
    "        min('class_std_cnt').alias('min'),\n",
    "        stddev('class_std_cnt').alias('stddev'),\n",
    "        count('class_std_cnt').alias('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa0937",
   "metadata": {},
   "source": [
    "#### sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e8a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame을 테이블로 등록\n",
    "cdf.createOrReplaceTempView('class')\n",
    "\n",
    "\n",
    "print('지역별 class 숫자를 계산해보자. 단 지역정보가 없는 데이터는 제외한다.')\n",
    "# sql query의 groupby 절은 select 기준열이나 집계합수를 제외한 나머지는 표기 불가 from view/table group by 기준열 having 조건절\n",
    "# spark.sql(\"select loc, count(*) as tot, class_std_cnt  from class group by loc having loc is not null;\").show() # groupby 기준이 아닌 열을 select에 표기\n",
    "spark.sql(\"select loc, count(*) as tot  from class group by loc having loc is not null;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''지역내 교육타입별 학생 수의 합과 평균을 구해보자. \n",
    "단  지역내 교육타입별 학생 숫자의 총 합이 300미만인 데이터는 제외한다.''')\n",
    "\n",
    "print('컬럼명이 sum(class_std_cnt) 이라니 너무 이상하다. 집계함수를 수행하고 별칭을 붙여보자')\n",
    "spark.sql('''select loc, sum(class_std_cnt) as tot, avg(class_std_cnt) as avg\n",
    "          from class \n",
    "          group by loc, teaching_type\n",
    "          having tot >= 300\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690dbb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('컬럼명이 sum(class_std_cnt) 이라니 너무 이상하다. 집계함수를 수행하고 별칭을 붙여보자')\n",
    "\n",
    "spark.sql('''select loc, sum(class_std_cnt) as tot, avg(class_std_cnt) as avg\n",
    "             from class \n",
    "             group by loc, teaching_type\n",
    "             having tot >= 300\n",
    "             ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63967ebe",
   "metadata": {},
   "source": [
    "## orderBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df14c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('반 학생 숫자를 기준으로 내림차순 정렬하라')\n",
    "cdf.orderBy(cdf.class_std_cnt.desc()).show(1)\n",
    "\n",
    "print('loc를 기준으로 오름차순 정렬하라, 이때 같은 지역끼리는 학교이름을 기준으로 내림차순 정렬하라')\n",
    "cdf.orderBy(cdf.loc.asc(), cdf.school.desc()).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ddfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습\n",
    "print('학교 종류를 기준으로 오름차순 정렬하라, 만약 school_type이 null인 행이 있다면 제일 위로 오게 하라')\n",
    "# 값이 null 인 행우선 표시, asc_nulls_first()\n",
    "cdf.orderBy(cdf.school_type.asc()).show(1)\n",
    "cdf.orderBy(cdf.school_type.asc_nulls_first()).show(1)\n",
    "cdf.orderBy(cdf.school_type.desc_nulls_first()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53b474",
   "metadata": {},
   "source": [
    "- orderBy(컬럼 객체, asc()/컬럼객체.desc())\n",
    "- 컬럼객체의 sort exp 메서드\n",
    "    - asc() : 오름차순\n",
    "    - desc() : 내림차순\n",
    "    - asc_nulls_first()/desc_null_first() : null값이 있으면 우선 위에 표시하고 null 이 아닌 data 는 오름/내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea49586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습\n",
    "\n",
    "print('학교 종류를 기준으로 오름차순 정렬하라, 만약 school_type이 null인 행이 있다면 제일 위로 오게 하라')\n",
    "# 값이 null인 행우선 표시. asc_nulls_first()\n",
    "cdf.orderBy(cdf.school_type.asc())\n",
    "cdf.orderBy(cdf.school_type.asc_nulls_first())\n",
    "cdf.orderBy(cdf.school_type.desc_nulls_first()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2e484",
   "metadata": {},
   "source": [
    "#### sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loc를 기준으로 오름차순 정렬하라, 이때 같은 지역끼리는 학교이름을 기준으로 내림차순 정렬하라')\n",
    "spark.sql('select * from class order by loc asc, school desc').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습\n",
    "print('학교 종류를 기준으로 오름차순 정렬하라, 만약 school_type이 null인 행이 있다면 제일 위로 오게 하라')\n",
    "spark.sql('''\n",
    "    select * from class order by school_type asc nulls first    \n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563e36c-afa1-4469-a3a5-0cfd6f973350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습\n",
    "print('학교 종류를 기준으로 오름차순 정렬하라, 만약 school_type이 null인 행이 있다면 제일 위로 오게 하라')\n",
    "spark.sql('''\n",
    "    select * from class order by school_type asc\n",
    "''')\n",
    "\n",
    "spark.sql('''\n",
    "    select * from class order by school_type asc nulls first\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b920813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학교 종류를 기준으로 내림차순 정렬하라, 만약 school_type이 null인 행이 있다면 제일 위로 오게 하라\n",
    "spark.sql('''\n",
    "    select * from class order by school_type desc nulls first\n",
    "''').show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
