# RNN(Recurrent Neural Network)

- 은닉층에서 나온 결과값이 다시 은닉층으로 돌아가 새로운 입력값과 연산을 수행하는 순환구조이다.

- 완전연결층, CNN과는 다르게 은닉층 -> 은닉층의 순환이 있다는 점에서 둘과는 차이가 있다.

- RNN에서는 다수의 RNN 계층 모두가 실제로는 '같은 계층'인 것이 피드포워드 신경망과의 차이점이라고 할 수 있다.

- 데이터가 순환되기 때문에 과거의 정보를 기억하는 동시에 최신 데이터로 갱신될 수 있음 -> 이러한 순환 구조는 시계열, 텍스트 데이터에 적합하다.

- Embedding 계층 -> 은닉 과정에서 예측을 실행한다.

## 순전파 (Feedforward)

- Neural Network 모델의 입력층부터 출력층(입력층 -> 은닉층 -> 출력층 순)까지 순서대로 변수들을 계산하고 저장하는 것을 의미한다.

- 순전파는 순서대로 진행되며 마지막에 결과 값이 나오기 때문에 결과를 이용해 가중치 조절을 할 수 없다.

- 최초 입력값으로부터 각 층마다 존재하는 가중치를 연산, 활성함수를 통과시키는 과정을 차례로 이어나가서 최종 layer까지 계산한 후 실제 label과 오차를 계산하는 것까지를 순전파라고 한다.

## 역전파 (Backpropagation)

- input과 output 값을 알고 있는 상태에서 신경망을 학습 시키는 방법, 지도 학습의 일종이라고 한다.

- 위의 순전파의 과정을 역행해서 실행하는 것이다. 역행하는 이유는 오차(loss)를 기반으로 가중치와 은닉상태를 업그레이드해 모델의 성능을 유지, 향상시킨다.

- RNN에서 역전파가 진행되면서(계측이 많을수록 많이 손실되는 것으로 보인다) 기울기 소실 문제가 발생한다. -> 이를 해결하기 위해서 LSTM을 활용한다.
