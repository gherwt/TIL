## 머신러닝3

### 지도학습알고리즘

- 학습, 훈련하기 위한 데이터(입력 변수)와 정답(타겟 변수)이 필요

- 데이터를 수집하고 훈련, 학습을 통해 예측을 위한 훈련을 진행 -> 정답을 맞추기 위해 훈련
    
### 비지도 학습 알고리즘

- 무언가를 맞출 수 없음(정답이 없기 때문에)

- 데이터를 잘 파악하거나 변형하는데 도움을 줌

- 특성의 분류을 통한 자료의 분류 - 군집화

#### 강화 학습

- 알고리즘이 행동한 결과로 얻은 보상을 사용해 학습, 가중치에 따른 결과를 파악하는 학습방법이다.

- 단적인 예로 어떤 데이터를  처음 분류했을 때 도미로 분류해 보상을 10을 얻고,
두번재 분류했을때는 빙어로 분류해  보상을 2를 얻었다면 강화학습은 이 보상의 결과를 놓고 해당 데이터에 6을 표기

- 그 후 해당 데이터에 8이라는 수치를 10으로 만들기 위해 알고리즘을 수정해 나가는 방식이 강화학습이다

### Train/Test 세트

#### 생선 분류

- 앞의 예에서 훈련데이터에서 도미를 100% 완벽하게 분류함

- 문제점 
  - 정답을 미리 알려주고 시험보는 것과 같은 결과라고 할 수 있다.
  - 분류 해놓은 자료를 입력하여 훈련, 예측을 진행하였기 때문이다

- 훈련한 데이터와 평가에 사용된 데이터가 달라야 함

- Train 세트 : `훈련에 사용`되는 데이터

- Test 세트 : `테스트에 사용`되는 데이터

```py
# 이전에 활용한 생선 데이터를 구분하지 않고 이를 활용하여 도미, 빙어를 구분하는 작업을 실행하고자 한다.

fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7,
               31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5,
               34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0,
               38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 
               450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

# l, w 로 구성된 list 를 생성한다.
# train/test set 만들기 위한 작업ㄴ
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1]*35 + [0]*14
```

### **훈련 데이터셋과 테스트 데이터셋으로 분리**

```py
# 훈련 35개 테스트 14개
# 훈련데이터(학습데이터)
train_input = fish_data[:35]
train_target = fish_target[:35]

# 테스트데이터(평가데이터)
test_input = fish_data[35:]
test_target = fish_target[35:]
```

### 빈 모델을 만들기 - 모델 구성하기

```py
# k-최근접 이웃 모델을 사용하여 머신러닝을 진행한다.
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()

# 만들어 놓은 훈련 data 를 통해서 test 를 진행하고 이를 평가한다.
kn.fit(train_input, train_target)
kn.score(test_input, test_target)
```

> 성능이 0.0 이 도출이 된다.

```py
# train 데이터에는 도미만 존재하고, test 데이터에는 빙어만 존재하기 때문이다.
print(train_target) 
print(test_target) 
```

> 즉, 편향된 데이터 셋 구성 때문에 잘못된 훈련과 학습이 일어났고 분류가 발생햇다.

### 편향되지 않게 올바른 train 데이터와 test 데이터 구성하기


```py
import numpy as np

# numpy 배열 사용해 배열로 바꿔준다.
input_arr = np.array(fish_data)
target_arr =  np.array(fish_target)

# 재현성을 확보하기 위해 난수 발생을 위한 seed 를 설정해준다.
# index로 사용될 배열을 생성하고 
np.random.seed(42)
index = np.arange(49)

# index 변수의 값을 변경, 순서를 무작위로 섞어준다.
np.random.shuffle(index) 
```

- `random.seed()`
  - 난수를 생성하기 위한 초기값 지정
  - seed를 지정하면 랜덤함수의 결과를 동일하게 재현할 수 있음

### 생성한 데이터를 분할

- input_arr: 물고기의 `길이와 무게를 포함하는 입력 데이터 배열`
- target_arr: 각 `입력 데이터에 대한 정답(레이블)을 포함하는 배열`

```py
# 데이터 분할
# train 데이터를 설정해준다.
train_input = input_arr[index[:35]]
train_target = target_arr[index[:35]]

# test
test_input = input_arr[index[35:]]
test_target = target_arr[index[35:]]
```

### 데이터 분할을 확인해 준다.

```py
import matplotlib.pyplot as plt

plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(test_input[:,0], test_input[:,1])
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

### 이전 오류를 개선한 머신러닝 실시

```py
# 훈련, 학습을 실시한다.
kn.fit(train_input, train_target)

# 평가해준다.
kn.score(train_input, train_target)

# 이미 정답이 완벽하게 정해져 있기 때문에 저오학도가 100이 나온다.
```

### Data Split과 모델 검증

- 언제 활용?
  - "충분히 큰" 데이터 세트를 가용할 때 활용한다.
  - "충분히 큰" 데이터가 없을 때에는 `교차 확인`(Cross Validation) 고려

- 왜 사용하는가?
  - 학습에 사용되지 않은 데이터를 사용하여 예측을 수행함으로써 모델의 일반적인 성능에 대한 적절한 예측을 함
    
- 어떻게, 어떤 방식으로?
  - 홀드-아웃(Hold-out)
  - 교차검증(Cross Validation,CV)

### 홀드-아웃 방식 진행과정

1. **데이터 나누기**: 전체 데이터를 Train set과 Test set으로 나눕니다. 일반적으로 `Train set`이 더 크며, 보통 7:3 또는 8:2의 비율을 사용.

2. **모델 학습**: `Train set을 사용하여 모델을 학습`시킵니다. 모델은 주어진 입력에 대한 출력을 예측하는 방법을 학습하게 됩니다.

3. **모델 평가**: `Test set을 사용하여 모델의 성능을 평가`합니다. 이 평가는 모델이 처음 보는 데이터에 대한 일반화 능력을 측정하는 데 사용됩니다.

4. **결과 분석**: 모델의 성능 및 예측 결과를 분석하고, 필요에 따라 모델을 조정하거나 개선합니다.

5. **일반화 확인**: 모델이 Test set에서 얼마나 일반화되는지 확인하여 실제 환경에서의 예측 성능을 예측합니다.

이 방식은 간단하고 빠르게 모델을 평가할 수 있어 많이 사용되지만, 데이터의 양이 적을 때 과적합의 영향을 받을 수 있다. 따라서 데이터가 충분하지 않은 경우, 교차 검증과 같은 다른 방법을 고려해야 한다.

