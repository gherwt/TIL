### 머신러닝 프로세스

- 데이터 가공/변환

- 모델 학습/예측

- 평가(Evaluation)

- 얼마나 오차가 적은가 -> 정확도

### 분류의 유형

#### 이진 분류

- 결정 클래스 값 종류의 유형에 따라 긍정/부정과 같은 `2개의 결과`값만을 가지는 분류

#### 멀티 분류

- `여러 개의 결정 클래스 값`을 가지는 분류

### 분류 모델의 평가 지표

#### 예측 대상이 범주형 데이터 경우

### 정확도(Accuracy)

- 실제 데이터와 예측 데이터가 `얼마나 같은지`를 판단하는 지표

- $ 정확도(Accuracy) =  \frac{예측 결과가 동일한 데이터 건수}{전체 예측 데이터 건수} $

- `직관적으로 모델 예측 성능을 나타내는 평가 지표`

- 그러나 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지는 않음

- 특히 정확도는 `불균형한 레이블 값 분포`에서 ML 모델의 성능을 판단할 경우, 적합한 지표가 아니다.
  
#### 정확도 지표가 ML 모델의 성능을 왜곡하는 예

- 타이타닉 예제는 수행 결과 정확도가 80%대 정도로 나온다. -> 탑승객이 남자인 경우보다 여자인 경우에 생존 확률이 높았기 때문인데

- 이러한 이유로 별다른 알고리즘 적용 없이 무조건 성별이 여자인 경우 생존, 남자인 경우 사망으로 예측해도 이와 비슷한 수치가 나올 수 있다.

- 알고리즘 성능이 좋지 않더라도 단지 성별 조건 하나만을 가지고도 높은 정확도를 나타내는 상황이 발생하게 된다.

- 이외에도 MNIST 데이터 세트가 모델의 성능을 왜곡하는 예 중 하나이다.

### 1. 타이타닉 생존자 예측을 통해 확인해보기

```py
import numpy as np
from sklearn.base import BaseEstimator # 학습하고 작업함.
from sklearn.preprocessing import LabelEncoder

# 아무런 학습을 하지 않고 성별에 따라 생존자를 예측하는 단순한 Classifier 생성, class 속성을 생성해준다.
# BaseEstimator 상속 받음

class MyDummyClassifier(BaseEstimator):
    
    # fit() 메소드는 아무것도 학습하지 않음. 학습을 위한 함수이다.
    # 일단 구성만을 한다. 더미 함수를 만들어줌
    def fit(self, X , y=None): # self는 인스턴스 자기 자신을 의미
        pass

    # predict() 메소드는 단순히 Sex feature(성별 구분)가 1 이면 0 , 그렇지 않으면 1 로 예측한다.
    def predict(self, X):
        pred = np.zeros( ( X.shape[0], 1 )) # 예측값 초기화 : 2차원 형태 (, 1) 예측해서 값을 넣어준다.
        for i in range (X.shape[0]) :
            if X['Sex'].iloc[i] == 1:   # '남자'이면
                pred[i] = 0  # 사망
            else :
                pred[i] = 1 # 생존
        
        return pred
```

```py
# Null 처리 함수(데이터의 전처리), null 값을 대표값으로 채운다.
def fillna(df):
    # 평균값으로 대체
    df['Age'].fillna(df['Age'].mean(), inplace=True)
    # N 으로 대체
    df['Cabin'].fillna('N', inplace=True)
    # N 으로 대체
    df['Embarked'].fillna('N', inplace=True)
    # 0으로 대체
    df['Fare'].fillna(0, inplace=True)
    return df

# 머신러닝 알고리즘에 불필요한 속성 제거(null이 많거나 불필요하다면)
def drop_features(df):

    # 불필요한 속성들을 제거해준다
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

# 레이블 인코딩 수행. 
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1] # 첫문자만 추출
    # 특성을 정해준다.
    features = ['Cabin','Sex','Embarked']
    for feature in features:
        le = LabelEncoder()
        # feature 에 맞게 학습을 해준다.
        le = le.fit(df[feature])
        # 데이터를 변환한다. 예측한다.
        df[feature] = le.transform(df[feature])
    return df

# 앞에서 설정한 Data Preprocessing 함수 호출
def transform_features(df):
    # 전처리
    df = fillna(df)
    # 필요없는 부분 버리기
    df = drop_features(df)
    df = format_features(df)
    return df
```

- 데이터 전처리 작업 후 타이타닉 생존자 예측

```py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. 
titanic_df = pd.read_csv('data/titanic_train.csv')
# 범주를 Survived 열로 설정해준다.
y_titanic_df = titanic_df['Survived']
# 정확도를 위해 따로 분리해서 학습을 진행해준다.
X_titanic_df= titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df) # 전처리를 진행
X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)
```

- 학습, 예측을 진행한다.

```py
# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. 
myclf = MyDummyClassifier()
myclf.fit(X_train, y_train)
mypred = myclf.predict(X_test)

# 정확도 점수 함수를 통해 정확도를 도출한다.
print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypred)))

# 약 79% 정확도를 가진다.
```

### 결과

- 단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도 결과는 78.77%로 꽤 높은 수치가 나올 수 있기에 정확도를 평가 지표로 사용할 때는 매우 신중해야 한다.

- 특히 정확도는 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우,적합한 지표가 아님

- 예를 들어 100개의 데이터가 있고 이 중에 90개의 데이터 레이블이 0,단 10개의 데이터 레이블이 1이라고 한다면 무조건 0으로 예측한 결과를 반환하는 ML 모델의 경우 정확도가 90%가 됨

- 데이터의 비율에 따라서 왜곡된 학습과 예측이 진행될 수 가 있음을 명심하자

### 2. MNIST 데이터 세트를 통해 왜곡을 확인하기.

- 0~9까지의 숫자 이미지의 픽셀 정보를 가지고 있고 이를 기반으로 숫자 Digit을 예측하는 데 사용

- 사이킷런의 load_digits() API를 통해 MNIST 데이터 세트 제공

### **이진 분류 문제로 변환**

- 불균형한 데이터 세트로 변형, 레이블 값이 7인 것만 True, 나머지 값은 모두 False로 변환 (0 ~ 9 중에서)

- True : 전체 데이터의 10%

- False : 90%

- 입력되는 모든 데이터를 False, 즉 0으로 예측하는 `classifier를 이용`해 정확도를 측정하면 약 90%에 가까운 예측 정확도를 나타냄

```py
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd

class MyFakeClassifier(BaseEstimator):
    def fit(self, X, y):
        pass
        
    # 번호를 생성한다.    
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)

# scikit-learn의 내장 데이터셋인 'digits' 데이터를 로드하는 함수
digits = load_digits()

digits
# {'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
#         [ 0.,  0.,  0., ..., 10.,  0.,  0.],
#         [ 0.,  0.,  0., ..., 16.,  9.,  0.],
#         ...,
#         [ 0.,  0.,  1., ...,  6.,  0.,  0.],
#         [ 0.,  0.,  2., ..., 12.,  0.,  0.],
#         [ 0.,  0., 10., ..., 12.,  1.,  0.]]),

digits.data.shape
# (1797, 64) 결과가 도출
```

- **7인 데이터는 1, 그외 데이터는 0으로 변환**, 예측, 학습을 시작.

```py
# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 
# 7번이 아니면 False이고 0으로 변환. 
y = (digits.target == 7).astype(int)

# 학습 / 테스트 데이터 세트로 분리 (default = 0.25) 사이즈를 따로 적용하지 않을 경우 
# 0.25 / 0.75
X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)

# 불균형한 레이블 데이터 분포도 확인. 
# 전체 1797 중 450 : 약 25% 테스트로 분리함.
print('레이블 테스트 세트 크기 :', y_test.shape)
print('테스트 세트 레이블 0 과 1의 분포도')
print(pd.Series(y_test).value_counts())

# 결과 값
# 레이블 테스트 세트 크기 : (450,)
# 테스트 세트 레이블 0 과 1의 분포도
# 0    405
# 1     45
# Name: count, dtype: int64

# Dummy Classifier로 학습/예측/정확도 평가
# 무조건 0 으로 판단하는 모델을 이용해서 predict 를 진행
# 결정값이 많은 데이터로 결정해버렸을 때 높은 수치가 나타난다.
fake_cl = MyFakeClassifier()
fake_cl.fit(X_train, y_train)
fakepred = fake_cl.predict(X_test)
accuracy = accuracy_score(y_test, fakepred)

print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy))
# 모든 예측을 0으로 하여도 정확도는:0.900
```

### 정확도 평가 지표의 맹점

- 아무것도 하지 않고 무조건 특정한 결과로 찍어도**데이터가 균일하지 않은 경우 높은 수치**가 나타날 수 있다.

- 결정값이 많은 데이터로 결정해버렸을 때 높은 수치가 나타난다. 그러므로 정확도만으로 평가를 판단하지 않는다.

- 이는 실제로 찾아야하는 값을 찾지 못해서 나타나는 문제이다.

### Confusion Matrix (오차 행렬)

- 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 `예측 오류`가 발생하고 있는지를 함께 나타내는 지표, 분류 모델의 성능을 평가하는데 사용한다.

- 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 가지고 맵핑되는지 나타냄

- 예측 클래스와 실제 클래스의 값 유형에 따라 TN, FP, FN, TP 형태

- TN, FP, FN, TP 값을 다양하게 결합해 분류 모델 예측 성능의 오류가 어떤 모습으로 발생하는지 알 수 있음
  - 얼마나 많이 맞혔는가를 계산 + 어떤 값을 얼마나 맞췄는지까지 고려한다.

- TN, FP, FN, TP는 예측 클래스와 실제 클래스의 Positive 결정값(1)과 Negative 결정값(0)의 결합에 따라 결정한다.

- 앞 문자 T/F(True/False): `예측값과 실제값이 '같은가/틀린가'` 의미
- 뒤 문자 N/P(Negative/Positive): `예측 결과 값`이 부정(0)/긍정(1) 의미
- 예 : TN (True Negative)
  - 앞 True : 예측 클래스 값과 실제 클래스 값이 같다는 의미

  - 뒤 Negative : 예측 값이 Negative 값이라는 의미

### 오차 행렬을 통해 다음과 같은 여러 가지 평가 지표를 계산할 수 있다

- 정확도(Accuracy): 전체 예측 중 올바르게 분류된 샘플의 비율. (TP + TN) / (TP + TN + FP + FN)

- 정밀도(Precision): Positive로 예측한 것 중 실제로 Positive인 비율. TP / (TP + FP)

- 재현율(Recall): 실제 Positive 중 모델이 Positive로 예측한 비율. TP / (TP + FN)

- F1 스코어(F1 Score): 정밀도와 재현율의 조화 평균으로 계산된 지표. 2x(정밀도x재현율) / (정밀도 + 재현율)

- **TN, FP, FN, TP 값은 Classifier 성능의 여러 면모를 판단할 수 있는 기반 정보 제공**

- 사이킷런은 오차행렬을 구하기 위해 `confusion_matrix() API` 제공

- 앞의 예제 MyFakeClassifier의 `예측 성능 지표를 오차행렬로 표현`

- MyFakeClassifier의 예측 결과인 fakepred와 실제 결과인 y_test를 confusion_matrix()의 인자로 입력해 오차행렬을 배열 형태로 출력

```py
from sklearn.metrics import confusion_matrix

# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력
# confusion_matrix(실제값, 예측값) 함수 사용

# 정확도 자체는 높다.
confusion_matrix(y_test , fakepred)
```

```md
array([[405,   0],
       [ 45,   0]], dtype=int64)

- 결과  
[[TN, FP],  
 [FN, TP]]
```

- MyFakeClassifier는 load_digits()에서 target=7인지 아닌지에 따라  
클래스 값을 `True/False 이진 분류로 변경한 데이터 세트를 사용`해서  
무조건 Negative로 예측하는 Classifier였고, 테스트 데이터 세트의 클래스 값 분포는 0이 450건, 1이 45건 이었음  

- TN : 전체 450건 데이터 중 무조건 Negative 0으로 예측해서 True가 된 결과 405건 = `실제값/예측값 동일`, `Negative`로 예측

- FP : Positive 1로 예측한 건수가 없으므로 0건 = `실제값/예측값 다름`, `Positive`로 예측

- FN : Positive 1인 건수 45건을  Negative 0으로 예측해서 False가 된 결과 45건 = `실제값/예측값 다름`, `Negative`로 예측  

- TP : Positive 1로 예측한 건수가 없으므로 0건 = `실제값/예측값 동일`, `Positive`로 예측

### 하지만 불균형한 이진 분류 데이터 세트에서 정확도의 맹점이 발생한다.

- **Positive 데이터 건수가 `매우 작아서` Positive 보다는 Negative로 예측 정확도가 높아지는 경향이 발생**  

- 10,000 건의 데이터 세트에서 9,900 건이 Negative이고 100건이 Positive라면 Negative로 예측하는 경향이 더 강해져서 TN은 매우 커지고 TP는 매우 작아지게 됨  

- 또한 Negative로 예측할 때 정확도가 높기 때문에 FN(Negative로 예측할 때 틀린 데이터 수)이 매우 작고, Positive로 예측하는 경우가 작기 때문에 FP 역시 매우 작아짐  

- 정확도 지표는 비대칭한 데이터 세트에서 Positive에 대한 예측 정확도를 판단하지 못한 채 Negative에 대한 예측 정확도만으로도 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게 됨  

- 그렇기 때문에 **불균형한 데이터 세트에서 정확도보다 더 선호되는 평가 지표**로 정밀도(Predision)와 재현율(Recall) 가 선호된다.

### 재현율(Recall)과 정밀도(Precision)

- Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표

- 앞의 MyFakeClassifier는 Positive로 예측한 TP값이 하나도 없기 때문에 정밀도와 재현율 값이 모두 0 이다.

### **정밀도와 재현율 계산 공식**

- 정밀도 = TP / (FP + TP) # 분모 : `정답`이 들어감, 분자 : 정답의 비중

> Positive로 예측한 데이터 중 정답의 비율

- 예측을 Positive로 한 대상 중에 예측과 실제 값이 `Positive로 일치`한 데이터의 비율, 예측한 양성 대 예측한(맞춘) 양성

- 공식의 분모인 (FP + TP)는 `예측을 Positive로 한 모든 데이터 건수` (예측한 양성)

- 분자인 TP는 `예측과 실제 값이 Positive로 일치`한 데이터 건수 (맞춘 양성)

- Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불림

- 재현율 = TP / (FN + TP) # 분모 : `예측한 결과값`, 분자 : 정답의 비중

> 정답이 positive인 대상중에 positive로 정답을 맞춘 비율

- `실제값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치`한 데이터의 비율, 실제 양성 대 예측한(맞춘) 양성 비율

- 공식의 분모인 (FN + TP)는 `실제값이 Positive`인 모든 데이터 건수 (실제 양성)

- 분자인 TP는 `예측과 실제 값이 Positive로 일치한 데이터 건수` (맞춘 양성)

- 민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불림

- 보통은 재현율이 정밀도보다 상대적으로 중요한 업무가 많지만  
정밀도가 더 중요한 지표인 경우도 있음
  - ex) 스팸 메일

- **재현율이 상대적으로 더 중요한 지표인 경우**
  - ex) 암 판단 모델, 금융 사기 적발 모델

### 재현율과 정밀도의 보완적 관계

- 재현율과 정밀도 모두 TP를 높이는 데 동일하게 초점을 맞춤

- 재현율은 FN(실제 Positive, 예측 Negative)를 낮추는데 초점을 맞추고,  정밀도는 FP를 낮추는데 초점을 맞춤

- 재현율과 정밀도는 서로 보완적인 지표로 분류의 성능을 평가하는데 적용

- 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것

- 반면에 둘 중 어느 한 평가 지표만 매우 높고, 다른 수치는 매우 낮은 결과를 나타내는 경우는 바람직하지 않다고 할 수 있다.

### MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정

- 사이킷런 API 사용
  - 정밀도 계산 : precision_score()
  - 재현율 계산 : recall_score()
  - 오차행렬 : confusion_matrix()

- 평가 간편 적용하기 위한 함수 작성 후 confusion_matrix / precision / recall 등의 평가를 한꺼번에 호출한다.

### MNIST에서 정밀도, 재현율 확인

```py
# 정밀도와 재현율 계산에 사용되는 예측값
# 앞에서 Dummy Classifier로 학습후 예측한 값: fakepred
# (앞에 다 있는 내용인데 흩어져 있어서 정밀도와 재현율 계산을 위해 다시 모아서 적음)
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator
import numpy as np
from sklearn.metrics import accuracy_score, precision_score , recall_score

class MyFakeClassifier(BaseEstimator):
    # fit( ) 메소드는 아무것도 학습하지 않음.
    def fit(self,X,y):
        pass
    
    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환
    def predict(self,X):
        return np.zeros( (len(X), 1) , dtype=bool)

# 앞에서 Dummy Classifier로 학습/예측에 사용한 데이터 세트
# digit 을 불러온다.
digits = load_digits()

# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환. 
y = (digits.target == 7).astype(int)

# 학습 / 테스트 데이터 세트로 분리 (default = 0.25))
X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)

# 예측값 : 앞에서 Dummy Classifier로 학습후 예측한 값
fakeclf = MyFakeClassifier()
fakeclf.fit(X_train , y_train)
fakepred = fakeclf.predict(X_test)
```

### 정밀도와 재현율 계산

```py
# 정밀도 계산 : precision_score(실제값, 예측값)
print("정밀도:", precision_score(y_test, fakepred))

# 재현율 계산 : recall_score(실제값, 예측값)
print("재현율:", recall_score(y_test, fakepred))

# 정확도는 90? but
# 정밀도: 0.0
# 재현율: 0.0
# 절대 사용할 수 없는 모델이다.
```

### 타이타닉 예제로 오차 행렬 및 정밀도, 재현율 구해서 예측 성능 평가

- 타이타닉 데이터를 로지스틱 회귀로 분류 수행

```py
from sklearn.metrics import accuracy_score, precision_score, recall_score , confusion_matrix

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred) # 오차행렬
    accuracy = accuracy_score(y_test, pred) # 정확도
    precision = precision_score(y_test, pred) # 정밀도
    recall = recall_score(y_test, pred) # 재현율 
    
    print(confusion) # 오차행렬을 반환

    print('정확도: {0:.3f}, 정밀도: {1:.3f}, 재현율: {2:.3f}'.format(accuracy, precision, recall))
```

- **타이타닉 예제에 오차행렬, 정밀도, 재현율 모두 구해서 예측 성능 평가**

```py
# 타이타닉 데이터 세트 전처리 작업 내용 
# 위에서 했던 작업을 다시 진행해주는 것이라고 보면 됨
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Null 처리 함수
def fillna(df):
    df['Age'].fillna(df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    df['Fare'].fillna(0, inplace=True)
    return df

# 머신러닝 알고리즘에 불필요한 속성 제거, 모델에 중요하지 않은 data 라고 판단, 티켓 등급 != 티켓id
def drop_features(df):
    df.drop(['PassengerId','Name','Ticket'],axis=1, inplace=True)
    return df

# 레이블 인코딩 수행. 
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder() # 데이터가 갯수가 유한, 범위가 적을 경우, 간격이 적을 경우
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

# 앞에서 설정한 Data Preprocessing 함수 호출
def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

- confusion matrix, accuracy, precision, recall 평가 수행

```py
# 로지스틱 회귀 기반으로 타이타닉 생존자 예측 후, 평가를 진행한다.
# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. 
# 저장한 타이타닉 데이터를 불러들여와서 작업을 진행한다
titanic_df = pd.read_csv('./data/titanic_train.csv')

y_titanic_df = titanic_df['Survived'] # y, target 값으로 적용

# 분리해서 학습, 분류를 진행한다.
X_titanic_df= titanic_df.drop('Survived', axis=1) 

# 전처리 함수를 호출
X_titanic_df = transform_features(X_titanic_df) 

# 결측치 등의 전처리가 마무리된 독립변수 df 를 이용, 데이터를 분할한다.
X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.20, random_state=11)

# 선형회귀를 기반으로 모델이다.
lr_clf = LogisticRegression(solver='liblinear')
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test , pred)

# 결과
# [[108  10]
# [ 14  47]]
#정확도: 0.866, 정밀도: 0.825, 재현율: 0.770

# 정밀도에 비해 재현율이 약간 높게 나왔지만 전체적으로 낮다.
```
