## 머신러닝8에서 진행했던 데이터들을 활용해서 교차검증 진행하기

### 교차검증을 통해 한번 더 확인

- **5 폴드 교차검증으로 모델별로 `RMSE`와 `평균 RMSE` 출력**

- 훈련/검증 세트를 5개로 나누어서 5번의 평가를 진행한다는 의미이다.

- 함수 생성를 생성하고 함수를 통해 평가를 진행하겠다.

- `cross_val_score`(model 객체, 학습데이터, 타겟데이터, scoring = 평가지표, cv = 폴드 수)

- scoring : 모델의 성능을 평가할 평가지표를 입력. accuracy, precision, recall, f1-score 등이 있다.
cv : 데이터를 분할할 폴드 수를 입력. 예를 들어, cv=5이면 데이터를 5개의 폴드로 분할하여 교차 검증을 수행함.

- 분류, 회귀에도 적용되는 함수이다.
  - 분류의 평가는 값이 클수록 좋은 성능을 가진다.
  - 회귀는 `R2값을 제외하고 값이 작아야 더 좋은 성능`을 가진다.

- 평가의 기준이 필요해 짐
  - 분류와 같이 `값이 클수록 좋은 성능`을 나타내기로 결정한다.
  - 회귀에 대해서는 평가된 성능값에 - 를 추가해서 `음수로 생성`하기로 함
  - 회귀 알고리즘의 평가점수는 음수값으로 반환이 된다. 그러므로 사용할 때 다시 양수로 변경해서 사용해야 한다.

```py
from sklearn.model_selection import cross_val_score

def get_avg_rmse_cv(models) : # 모델 각 각에 대해서 함수를 적용, 평균을 만들겠다. 
    
    # 모델마다 5번 교차검증을 진행, 검증 평가의 평균을 반환한다.
    for model in models :
        
        # 분류, 회귀에도 적용되는 함수
        rmse_list = np.sqrt(- cross_val_score(model, X_train, y_train,
                        # 성능 평가를 위해 negative 붙여줌, 직관적으로 동일한 평가를 하기 위해서이다.
                        # neg_mean_squared_error 결과 값이 음수로 반환 그래서 앞에 - 붙여 양수변환해준다.ㅈ
                        # 5 개의 rmse 값이 반환된다. 
                       scoring = 'neg_mean_squared_error', cv = 5))
    
        # 검증 평가의 평균 RMSE(Root Mean Squared Error)를 반환
        # 반환된 rmse 값의 평균을 구한다.
        rmse_avg = np.mean(rmse_list)

        # 해당되는 모델의 이름, rmse_list 값을 출력해준다.
        print('\n{0} CV RMSE 값 리스트: {1}'.format( model.__class__.__name__, np.round(rmse_list, 3)))

        print('{0} CV 평균 RMSE 값: {1}'.format( model.__class__.__name__, np.round(rmse_avg, 3)))     

# 앞에서 학습한 lr_reg, ridge_reg, lasso_reg 모델의 CV RMSE값 출력           
models = [lr_reg, ridge_reg, lasso_reg]
get_avg_rmse_cv(models)
```

```md
이런 식으로 결과가 도출된다.
LinearRegression CV RMSE 값 리스트: [0.132 0.126 0.166 0.25  0.148]
LinearRegression CV 평균 RMSE 값: 0.164

Ridge CV RMSE 값 리스트: [0.128 0.118 0.148 0.212 0.148]
Ridge CV 평균 RMSE 값: 0.151

Lasso CV RMSE 값 리스트: [0.182 0.152 0.213 0.28  0.199]
Lasso CV 평균 RMSE 값: 0.205
```

### 결과

- 5개 폴드 세트로 학습한 후 평가해도 여전히 라쏘 모델이 다른 회귀 모델에 비해 성능이 떨어는 것을 확인, 개선이 필요함을 확인할 수 있다.

### **리지/라쏘 모델에 대해 `alpha 하이퍼파라미터 튜닝 후` 재학습/예측/평가**

#### `GridSearchCV`

- 교차검증과 더불어서 전달된 파라미터 딕셔너리를 활용해서 하이퍼파라미터 적용도 진행해주는 함수

- 다양한 값으로 파라미터를 설정하는 이유는 모델의 성능을 최적화하기 위함이다. 각 모델의 특성에 따라 적절한 파라미터 값이 다르기 때문에, 다양한 값으로 파라미터를 설정하여 최적의 파라미터를 찾아준다.

- ex) 3폴드 교차검증과 하이퍼파라미터 alpha 에 대해서 [0.001, 0.1, 1] 세 값을 적용하기로함
  - alpha 값이 0.001 일 때 3폴드 교차검증 
  - alpha 값이 0.1 일 때 3폴드 교차검증
  - alpha 값이 1 일 때 3폴드 교차검증
  - 총 9번의 교차검증을 진행한다.

- 교차검증 진행 후 저장되는 값들
  - gcv.best_score_ : 교차검증 후 가장 성능이 좋은 평가값
  - gcv.best_params_: 가장 좋은 성능의 평가가 나올 때의 하이퍼파라미터 값
  - gcv.best_estimator : 최적 파라미터로 재학습된 모델

```py
from sklearn.model_selection import GridSearchCV
# 모델과 하이퍼 파라미터 딕셔너리 객체를 받아서
# 최적화 작업의 결과를 표시하는 함수
# 릿지 모델과 라쏘 모델의 최적화 alpha 값 추출

def get_best_params(model, params):
    # GridSearchCV 함수로 교차검증을 진행
    #  머신러닝 모델의 최적 파라미터를 찾는다.
    grid_model = GridSearchCV(model, param_grid = params,
                             scoring = 'neg_mean_squared_error', cv = 5)
    # grid 모델로 학습을 진행시켜준다.
    grid_model.fit(X_train, y_train)
    rmse = np.sqrt(-1 * grid_model.best_score_)
 
    print('{0} 5 CV 시 최적 RMSE 값: {1}, 최적 alpha:{2}'.format(model.__class__.__name__,
                                        np.round(rmse, 4), grid_model.best_params_))
    
    return grid_model.best_estimator_ # 최적 파라미터로 재학습되어 저장된 모델 반환
```

```py

# 최적 파라미터 값을 찾기 위해서 alpha 값을 설정해준다..
ridge_params = {'alpha' : [0.05,0.1,1,5,8,10,12,15,20]}
lasso_params = {'alpha' : [0.001,0.005, 0.008,0.05, 0.03, 0.1, 0.5, 1.5,10]}

best_ridge = get_best_params(ridge_reg, ridge_params)
best_lasso = get_best_params(lasso_reg, lasso_params)
```

```md
값이 이렇게 도출된다.
Ridge 5 CV 시 최적 RMSE 값: 0.1498, 최적 alpha:{'alpha': 10}
Lasso 5 CV 시 최적 RMSE 값: 0.1522, 최적 alpha:{'alpha': 0.001}
```

### 결과(결과 확인 후 정리)

- 릿지 모델 : alpha가  10 에서 최적 평균 RMSE 가 0.1498  
- 라쏘 모델 : alpha가 0.001  에서 최적 평균 RMSE가  0.1522
- **라쏘 : alpha 최적화한 후 예측성능이 향상 됨( 0.205 -> 0.152 )**

### 이를 재학습 후 평가

```py
lasso_reg = Lasso(alpha = 0.001)
lasso_reg.fit(X_train, y_train)

# 모든 모델의 RMSE 출력
models = [lr_reg, ridge_reg, lasso_reg]
get_rmses(models)
```

```md
- 결과값들을 반환하고 확인해준다.
LinearRegression 로그 변환된 RMSE: 0.132
Ridge 로그 변환된 RMSE: 0.128
Lasso 로그 변환된 RMSE: 0.12

[0.13209246889873053, 0.12813308035944904, 0.12037308692249254]
```

```py

# 모든 모델의 회귀 계수 시각화 
models = [lr_reg, ridge_reg, lasso_reg]
visualize_coefficient(models)
```

![Alt text](%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.png)

### 데이터 세트를 추가적으로 가공해서 모델 튜닝을 좀 더 진행

- 세 모델 모두 GrlivArea(주거공간크기)가 회귀 계수가 가장 높은 피처가 됨
- 주거공간의 크기가 주택 가격에 미치는 영향이 제일 높다는 의미

- 상식선에서의 결과가 도출되었다고 할 수 있다.

### **3개 모델에서 가장 큰 회귀계수를 가지는 GrLivArea(주거 공간 크기) 피처의 데이터 분포를 살펴봄**

- house_df_org : 어떤 전처리도 하지 않은 data
- SalePrice 는 로그변환 진행
- GrLivArea 는 로그변환 전처리 진행

```py
# 주거공간(전용면적)과 집가격과의 관계
plt.scatter(x = house_df_org['GrLivArea'], y = house_df_org['SalePrice'])
plt.ylabel('SalePrice', fontsize=15)
plt.xlabel('GrLivArea', fontsize=15)
plt.show()
```

![Alt text](<주거공간 집가격 관계.png>)

#### 그래프 해석

- 일반적으로 주거 공간이 큰 집일수록 가격이 비싸기 때문에 양의 상관도가 높음을 알 수있다 but. 오른쪽 끝의 2개의 데이터는 일반적인 관계에서 많이 벗어나 있다.
- 잘못 수집된 것보다는 기준이 다르다고 간주하고 보면 크기는 큰데 가격은 매우 낮음 => 이상치로 간주하고 삭제하도록 한다.

#### **이상치 데이터 삭제 후 재 학습/예측/평가**

```py
# 오른쪽 끝에 돌출된 이상치들을 삭제해준다.
cond1 = house_df_ohe['GrLivArea'] > np.log1p(4000) 
cond2 = house_df_ohe['SalePrice'] < np.log1p(500000)
outlier_index = house_df_ohe[cond1 & cond2].index
outlier_index
# 이런 결과가 도출 Index([523, 1298], dtype='int64')

print('아웃라이어 레코드 index :', outlier_index.values)

print('아웃라이어 삭제 전 house_df_ohe shape:', house_df_ohe.shape)
# DataFrame의 index를 이용하여 아웃라이어 레코드 삭제. 
house_df_ohe.drop(outlier_index, axis = 0, inplace = True)
print('아웃라이어 삭제 후 house_df_ohe shape:', house_df_ohe.shape)
```

- 결과값들

```md
아웃라이어 레코드 index : [ 523 1298]
아웃라이어 삭제 전 house_df_ohe shape: (1460, 275)
아웃라이어 삭제 후 house_df_ohe shape: (1458, 275)
```

- 이상치가 제거된 `house_df_ohe 기반`으로 `피처/타깃 데이터 세트 다시 생성`

```py
y_target = house_df_ohe['SalePrice']
X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)
X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)
```

- `릿지와 라쏘 모델의 최적화 수행`(best_params 함수를 사용한다)

```py
# 최적 파라미터 찾기.
ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }
lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }

best_ridge = get_best_params(ridge_reg, ridge_params)
# Ridge 5 CV 시 최적 RMSE 값: 0.1161, 최적 alpha:{'alpha': 5}

best_lasso = get_best_params(lasso_reg, lasso_params)
# Lasso 5 CV 시 최적 RMSE 값: 0.1154, 최적 alpha:{'alpha': 0.001}
```

- 이상치를 제거한 데이터 세트를 기반으로 분할된 데이터에 `RMSE 수치 및 회귀 계수 시각화` 진행

```py
# 선형회귀 모델 생성
lr_reg = LinearRegression()
lr_reg.fit(X_train, y_train)

# 릿지 모델 생성, 최적 파라미터 대입
ridge_reg = Ridge(alpha=8)
ridge_reg.fit(X_train, y_train)

# 라쏘 모델 생성, 최적 파라미터 대입
lasso_reg = Lasso(alpha=0.001)
lasso_reg.fit(X_train, y_train)

# 모든 모델의 RMSE 출력
models = [lr_reg, ridge_reg, lasso_reg]
get_rmses(models)
```

```md
LinearRegression 로그 변환된 RMSE: 0.128
Ridge 로그 변환된 RMSE: 0.104
Lasso 로그 변환된 RMSE: 0.1
[0.12834003696587168, 0.10354846839136342, 0.1001723920963491]
```

- **왜곡값이 큰 변수에 로그변환, 규제 적용에 대한 alpha 튜닝, 이상치 처리된 데이터가 가장 좋은 성능을 보이는 모델을 생성한다**

```py
# 모든 모델의 회귀 계수 시각화 
models = [lr_reg, ridge_reg, lasso_reg]
visualize_coefficient(models)
```

![Alt text](<처리후 시각화.png>)

### 결론

- 이상치 데이터를 제거 : 예측수치가 크게 향상됨

- GrLivArea 속성이 회귀 모델에서 차지하는 영향도 크기 때문에 이상치 제거가 성능개선에 큰 의미를 가진다.

- 회귀에서는 중요한 영향을 미치는 피처를 위주로 이상치 데이터를 찾으면 효과가 큼

#### tip

- 보통 머신러닝 프로세스 중에서 데이터 전처리는 알고리즘 적용 수행하기 이전에 진행하지만, 완벽하게 전처리를 수행할 필요는 없음

- 대략의 데이터 가공을 진행하고 모델 최적화를 진행 한 후, 결과를 기반으로 다시 여러가지 전처리를 진행하는것이 바람직하다
