# 선형회귀

- 하나 이상의 특성과 연속적인 타깃 변수 사이의 관계를 모델링 하는 것이다.

- 연속적인 출력 값을 예측하는 것

- 특성이 1개 인 선형 모델공식

  - Y = W0 + W1*X -> W0, W1 을 잘 예측하는 것이 목표

  - where W0 : y축 절편, W1 : 특성의 `가중치`

  - 목적 : 특성과 타깃 사이의 `관계를 나타내는 선형 방정식의 가중치(W)를 학습`하는 것

## 선형회귀 모델의 훈련과 비용함수

- 모델의 훈련이란?

  ✔ 모델이 훈련 데이터에 잘 맞도록 모델 `파라미터를 설정`하는 것

  ✔ `모델이 훈련 데이터에 얼마나 잘 들어맞는지 측정`해야 함 -> 비용함수로 확인한다.

- MSE (Mean Squared Error)

  1. 회귀 모델의 주요 손실 함수

  2. 참값(yi 값)과 예측값(^ 붙어있는 것)의 차이인 `오차들의 제곱 평균`으로 정의

  3. 제곱을 해주기 때문에 이상치(outlier)에 민감하다.

- MAE (Mean Absolute Error)

  1. 참값과 예측값의 차이인 `오차들의 절대값 평균`
  
  2. MSE보다 이상치에 덜 민감하다

- RMSE (Root Mean Squared Error)

  1. MSE에 `root`을 취해 준 것

  2. 참값과 비슷한 값으로 변환하기 때문에 해석이 쉬워진다. -> 실제 오차 값인지를 비슷하게 확인할 수 있게 해주기 때문이다.

### 보통 quadratic(2차 곡선형태) 형태의 미분 편의성이 좋기 때문에, 회귀 모형의 비용함수로 MSE를 많이 사용한다

### 선형회귀 모델의 최적화 방법

- 정규 방정식

  - 비용 함수를 최소화하는 θ 값을 찾기 위한 해석적 방법
  - 정규방정식은 n개의 특성수에 따라서 (n+1) x (n+1)의 X XT 역행렬을 계산한다.
  - 이 말은 특성의 수가 많아지면 정규방정식의 구현속도가 느려진다. -> 행렬의 수가 증가하기 때문에
  - 하지만 다행히도 `모델의 복잡도가 훈련 세트의 샘플 수와 특성 수에 선형적으로 증가`한다. 일정하게 증가한다.
  - 메모리 공간이 충분하다면 큰 훈련 세트도 효율적으로 처리 가능
